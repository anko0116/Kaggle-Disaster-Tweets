{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install tensorflow-text\n!pip install -q tf-models-official\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport re\nimport requests\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom official.nlp import optimization  # to create AdamW optimizer\nfrom sklearn.model_selection import StratifiedShuffleSplit\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nEMOJIS = {':)': 'smile', ':-)': 'smile', ';d': 'wink', ':-E': 'vampire', ':(': 'sad', \n          ':-(': 'sad', ':-<': 'sad', ':P': 'raspberry', ':O': 'surprised',\n          ':-@': 'shocked', ':@': 'shocked',':-$': 'confused', ':\\\\': 'annoyed', \n          ':#': 'mute', ':X': 'mute', ':^)': 'smile', ':-&': 'confused', '$_$': 'greedy',\n          '@@': 'eyeroll', ':-!': 'confused', ':-D': 'smile', ':-0': 'yell', 'O.o': 'confused',\n          '<(-_-)>': 'robot', 'd[-_-]b': 'dj', \":'-)\": 'sadsmile', ';)': 'wink', \n          ';-)': 'wink', 'O:-)': 'angel','O*-)': 'angel','(:-D': 'gossip', '=^.^=': 'cat'}\n\ndef remove_punct(tweet):\n    return re.sub(r'[^\\w\\s]', '', tweet)\ndef remove_word(word):\n    def remove_specific(tweet):\n        return tweet.replace(word, '')\n    return remove_specific\ndef remove_url(string):\n    return re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%|\\-)*\\b', '', string)\ndef remove_html(string):\n    return re.sub(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', '', string)\ndef remove_useless_char(string):\n    thestring = re.sub(r'[^a-zA-Z\\s]','', string)\n    thestring = re.sub(r'\\b\\w{1,2}\\b', '', thestring)\n    return re.sub(' +', ' ', thestring) \ndef remove_emojis(string):\n    for emoji in EMOJIS.keys():\n        string = string.replace(emoji, \"EMOJI\" + EMOJIS[emoji])  \n    return string\ndef make_lowercase(string):\n    return string.lower()\ndef remove_nums(string):\n    return re.sub(r'\\d+', '', string)\n\ndef preprocess(dataset):\n    # Helpful link for tokenization\n    # https://www.kdnuggets.com/2020/03/tensorflow-keras-tokenization-text-data-prep.html\n    dataset[\"text\"] = dataset[\"text\"].apply(make_lowercase)\n    dataset[\"text\"] = dataset[\"text\"].apply(remove_url)\n    dataset[\"text\"] = dataset[\"text\"].apply(remove_html)\n    dataset[\"text\"] = dataset[\"text\"].apply(remove_punct)\n    dataset[\"text\"] = dataset[\"text\"].apply(remove_nums)\n    dataset[\"text\"] = dataset[\"text\"].apply(remove_emojis)\n    return dataset        ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T05:59:03.976757Z","iopub.execute_input":"2022-01-09T05:59:03.977199Z","iopub.status.idle":"2022-01-09T05:59:23.567268Z","shell.execute_reply.started":"2022-01-09T05:59:03.977051Z","shell.execute_reply":"2022-01-09T05:59:23.566358Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Load train dataset and preprocess the texts\ntrain_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/train.csv\")\ntrain_df = train_df.drop(columns=[\"id\", \"keyword\", \"location\"])\ntrain_df = preprocess(train_df)\n# Load test dataset and preprocess the texts\ntest_df = pd.read_csv(\"/kaggle/input/nlp-getting-started/test.csv\")\ntest_df = test_df.drop(columns=[\"keyword\", \"location\"])\ntest_df['text'] = test_df['text'].replace(\"\", \"empty\") # For tweets with empty strings\ntest_df = preprocess(test_df)\n\nsplit = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=100)\nstrat_train = []\nstrat_val = []\nfor train_index, val_index in split.split(train_df[\"text\"], train_df['target']):\n    strat_train.append(train_df.loc[train_index])\n    strat_val.append(train_df.loc[val_index])\nstrat_train = pd.DataFrame(strat_train[0], columns=['text', 'target'])\nstrat_val = pd.DataFrame(strat_val[0], columns=['text', 'target'])\nx_train = strat_train[\"text\"]\ny_train = strat_train[\"target\"]\nx_val = strat_val[\"text\"]\ny_val = strat_val[\"target\"]\n\nsns.countplot(y_train)\nsns.countplot(y_val)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:59:23.569226Z","iopub.execute_input":"2022-01-09T05:59:23.570166Z","iopub.status.idle":"2022-01-09T05:59:24.093295Z","shell.execute_reply.started":"2022-01-09T05:59:23.570053Z","shell.execute_reply":"2022-01-09T05:59:24.092490Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"bert_preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\nbert_model_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\ntfhub_handle_encoder = bert_model_url\ntfhub_handle_preprocess = bert_preprocess_url\n\ndef build_classifier_model():\n  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n  encoder_inputs = preprocessing_layer(text_input)\n  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n  outputs = encoder(encoder_inputs)\n  net = outputs['pooled_output']\n  net = tf.keras.layers.Dense(1, activation='sigmoid', name='classifier')(net)\n  return tf.keras.Model(text_input, net)\n\nclassifier_model = build_classifier_model()\ntf.keras.utils.plot_model(classifier_model)\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\nmetrics = tf.metrics.BinaryAccuracy()\nopt = tf.keras.optimizers.Adam(learning_rate=1e-5)\nclassifier_model.compile(optimizer=opt,\n                         loss=loss,\n                         metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:59:24.094992Z","iopub.execute_input":"2022-01-09T05:59:24.095263Z","iopub.status.idle":"2022-01-09T05:59:45.323562Z","shell.execute_reply.started":"2022-01-09T05:59:24.095216Z","shell.execute_reply":"2022-01-09T05:59:45.322630Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"history = classifier_model.fit(x=x_train,\n                               y=y_train,\n                               validation_data=(x_val, y_val),\n                               epochs=2,\n                               callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=1, restore_best_weights=True)],\n                               batch_size=16,\n                              )","metadata":{"execution":{"iopub.status.busy":"2022-01-09T05:59:45.326405Z","iopub.execute_input":"2022-01-09T05:59:45.326708Z","iopub.status.idle":"2022-01-09T09:20:22.566122Z","shell.execute_reply.started":"2022-01-09T05:59:45.326666Z","shell.execute_reply":"2022-01-09T09:20:22.565146Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Save output to csv file\npredictions = classifier_model.predict(test_df[\"text\"])\npredictions = np.round(predictions).astype(np.short)\n\noutput_df = pd.DataFrame(test_df['id'])\noutput_df['target'] = predictions\n\nout = output_df.to_csv('hyukahn_rnn.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T09:20:22.569720Z","iopub.execute_input":"2022-01-09T09:20:22.570184Z","iopub.status.idle":"2022-01-09T09:33:50.966397Z","shell.execute_reply.started":"2022-01-09T09:20:22.570137Z","shell.execute_reply":"2022-01-09T09:33:50.965613Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"Largest small BERT performance bad <br/>\nElectra <br/>\nExpert-wikibook - bad <br/>\nBERT uncased - <br/>","metadata":{}},{"cell_type":"code","source":"# Print to console in case Kaggle notebook times out\npredictions = classifier_model.predict(test_df[\"text\"])\npredictions = np.round(predictions).astype(np.short)\n\noutput_df = pd.DataFrame(test_df['id'])\noutput_df['target'] = predictions\n\nwith pd.option_context('display.max_rows', None, 'display.max_columns', None):  # more options can be specified also\n    print(output_df)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T09:33:50.967881Z","iopub.execute_input":"2022-01-09T09:33:50.968130Z","iopub.status.idle":"2022-01-09T09:46:17.918774Z","shell.execute_reply.started":"2022-01-09T09:33:50.968097Z","shell.execute_reply":"2022-01-09T09:46:17.917510Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}